# Docker Compose for bicleaner-service
#
# Usage:
#   GPU:  docker compose up -d                    (auto-detects GPU)
#   CPU:  docker compose --profile cpu up -d      (force CPU mode)
#
#   curl http://localhost:8057/health

x-common: &common
  build:
    context: .
    dockerfile: Dockerfile
    # Default: GPU image (tensorflow/tensorflow:2.15.0-gpu)
    # Override with args for CPU
  container_name: bicleaner-service
  ports:
    - "8057:8080"
  environment:
    - BICLEANER_MODEL_TYPE=xlmr
    - BICLEANER_MODEL_PATH=bitextor/bicleaner-ai-full-en-xx
    - BICLEANER_BATCH_SIZE=32
    - BICLEANER_MAX_BATCH_SIZE=100
    # Performance settings
    - BICLEANER_INFERENCE_WORKERS=2
    - BICLEANER_MAX_CONCURRENT_REQUESTS=10
    - BICLEANER_INFERENCE_TIMEOUT_SEC=60
  volumes:
    - bicleaner_cache:/cache/huggingface
  restart: unless-stopped
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 120s

services:
  # Default service with GPU support
  bicleaner-service:
    <<: *common
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # CPU-only variant (use with --profile cpu)
  bicleaner-service-cpu:
    <<: *common
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: tensorflow/tensorflow:2.15.0
    container_name: bicleaner-service-cpu
    profiles:
      - cpu
    environment:
      - BICLEANER_MODEL_TYPE=xlmr
      - BICLEANER_MODEL_PATH=bitextor/bicleaner-ai-full-en-xx
      - BICLEANER_BATCH_SIZE=16
      - BICLEANER_MAX_BATCH_SIZE=50
      - CUDA_VISIBLE_DEVICES=-1
      # Performance settings (CPU: more workers, same limits)
      - BICLEANER_INFERENCE_WORKERS=4
      - BICLEANER_MAX_CONCURRENT_REQUESTS=10
      - BICLEANER_INFERENCE_TIMEOUT_SEC=120

volumes:
  bicleaner_cache:
    name: bicleaner_hf_cache
